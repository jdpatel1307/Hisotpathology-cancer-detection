{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1SfI58VJe58M1QQtcxx_1Gw3apcK58ePZ","timestamp":1668275780909}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Histopathologic CNN Analyzer\n","\n","This architecture is based on the LeNet network as described in Dive Into Deep Learning (2021, Aston Zhang, Zachary C. Lipton, Mu Li, and Alexander J. Smola), Section 6.6.1.\n","\n","It has been substantially modified to incorporate improvements from the literature."],"metadata":{"id":"oeenAYX_9m0F"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"LmjkOAisxMcV"},"outputs":[],"source":["import torch.nn as nn\n","import torchvision.transforms as tx"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rd__K_iiw-Pq"},"outputs":[],"source":["class Histopath_CNN(nn.Module):\n","\n","    def __init__(self, debug):\n","        super(Histopath_CNN, self).__init__()\n","        \n","        self.debug = debug\n","\n","        # Image Pre-Processing\n","        self.conv0 = nn.Sequential(\n","            nn_debug(debug),\n","            # Add standard center cropping based on numerous trials of larger and \n","            #   smaller data values for the Histopathologic Cancer dataset.\n","            #   The labelled portion of the images are within the 32x32 center.\n","            #TODO probably move out to pre-processing pipeline, but this requires\n","            #   replacement of the input data, not addition to.\n","            tx.CenterCrop(54)\n","        )\n","        self.conv1 = nn.Sequential(\n","            # Print input shape\n","            nn_debug(debug),\n","            # Convolutional layer\n","            nn.Conv2d(3, 12, kernel_size=5, padding=2),\n","            # Normalize values across the batch; wants a larger batch size\n","            #   e.g. > 50; may aid training by reducing internal covariate shift -\n","            #   making it less sensitive to spatial arrangement of parameters\n","            nn.BatchNorm2d(12),\n","            # Activation function - non-linear function - ReLU offers better \n","            #  training performance due to its less gentle curve than other actives\n","            nn.ReLU(),\n","            # Pooling 'steps back' from the details a little bit in order to help\n","            #   generalize the image\n","            nn.MaxPool2d(kernel_size=2, stride=2)\n","      )\n","        self.conv2 = nn.Sequential(\n","            nn_debug(debug),\n","            nn.Conv2d(12, 24, kernel_size=5),\n","            nn.BatchNorm2d(24),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=3, stride=2),\n","            # Collapse the 3D data into a 1D input for the linear units\n","            nn.Flatten()\n","        )\n","        # Traditional linear network for classification learning\n","        self.fc1 = nn.Sequential(\n","            nn_debug(debug),\n","            nn.Linear(2904, 4240),\n","            nn.ReLU()\n","        )\n","        self.fc2 = nn.Sequential(\n","            nn_debug(debug),\n","            nn.Linear(4240, 1228),\n","            nn.ReLU()\n","       )\n","        self.fc3 = nn.Sequential(\n","            nn_debug(debug),\n","            nn.Linear(1228, 1),\n","            # Apply Sigmoid activation in order to get a smoother probability\n","            #   curve, which is required by the BinaryCrossEntropy Loss function\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, x):\n","        # Image tx\n","        x=self.conv0(x)\n","\n","        # convolutions\n","        x = self.conv1(x)\n","        x = self.conv2(x)\n","\n","        # FC layers\n","        x = self.fc1(x)\n","        x = self.fc2(x)\n","        x = self.fc3(x)\n","\n","        return x"]},{"cell_type":"code","source":["class nn_debug(nn.Module):\n","    def __init__(self, debug):\n","        super(nn_debug, self).__init__()\n","        self.debug = debug\n","\n","    def forward(self, x):\n","        if self.debug:\n","            print(f'## Input: {x.shape}')\n","        return x"],"metadata":{"id":"EAzb_sK97Axj"},"execution_count":null,"outputs":[]}]}