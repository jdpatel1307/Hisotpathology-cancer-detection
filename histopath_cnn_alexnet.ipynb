{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1Z_9RvpA8IcIsaoR2C1RhtU1uCRKLPLM6","timestamp":1668552878691},{"file_id":"1SfI58VJe58M1QQtcxx_1Gw3apcK58ePZ","timestamp":1668275780909}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Histopathologic CNN Analyzer\n","\n","This architecture is based on the AlexNet network as described in Dive Into Deep Learning (2021, Aston Zhang, Zachary C. Lipton, Mu Li, and Alexander J. Smola), Section 6.6.1.\n","\n","It has been slightly modified to account for the smaller image sizes."],"metadata":{"id":"oeenAYX_9m0F"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"LmjkOAisxMcV"},"outputs":[],"source":["import torch.nn as nn\n","import torchvision.transforms as tx"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rd__K_iiw-Pq"},"outputs":[],"source":["class Histopath_CNN(nn.Module):\n","\n","    def __init__(self, debug):\n","        super(Histopath_CNN, self).__init__()\n","        \n","        self.debug = debug\n","\n","        # Image Pre-Processing\n","        self.conv0 = nn.Sequential(\n","            nn_debug(debug),\n","            # Add standard center cropping based on numerous trials of larger and \n","            #   smaller data values for the Histopathologic Cancer dataset.\n","            #   The labelled portion of the images are within the 32x32 center.\n","            tx.CenterCrop(54)\n","        )\n","\n","        self.conv = nn.Sequential(\n","            # Print input shape\n","            nn_debug(debug),\n","            # Conv Layer 1\n","            nn.Conv2d(3, 96, kernel_size=7, stride=1, padding=2),\n","            nn_debug(debug),\n","            # Activation function - non-linear function - ReLU offers better \n","            #  training performance due to its less gentle curve than other activations\n","            nn.BatchNorm2d(96),\n","            nn.Tanh(),\n","            # Pooling 'steps back' from the details a little bit in order to help\n","            #   generalize the image\n","            nn.MaxPool2d(kernel_size=4, stride=1, padding=2),\n","            nn_debug(debug),\n","\n","            # Conv Layer 2\n","            nn.Conv2d(96, 192, kernel_size=3, stride=2, padding=1),\n","            nn.BatchNorm2d(192),\n","            nn_debug(debug),\n","            nn.Tanh(),\n","            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n","\n","            # Three consecutive convo layers\n","            #nn_debug(debug),\n","            nn.Conv2d(192, 128, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(128),\n","            nn.Tanh(),\n","\n","            #nn_debug(debug),\n","            #nn.Conv2d(128, 32, kernel_size=3, stride=1, padding=1),\n","            #nn.BatchNorm2d(32),\n","            #nn.Tanh(),\n","\n","            nn_debug(debug),\n","            nn.Conv2d(128, 64, kernel_size=4, stride=2, padding=1),\n","            nn.BatchNorm2d(64),\n","            nn.Tanh(),\n","\n","            nn_debug(debug),\n","            nn.MaxPool2d(kernel_size=4, stride=2, padding=1),\n","            # Collapse the 3D data into a 1D input for the linear units\n","            nn_debug(debug),\n","            nn.Flatten()\n","        )\n","\n","        # Traditional linear network for classification learning\n","        self.fc = nn.Sequential(\n","            nn_debug(debug),\n","\n","            # FC Layer 1\n","            nn.Linear(2304, 2880),\n","            nn.ReLU(),\n","            #nn.Dropout(p=0.5),\n","\n","            # FC Layer 2\n","            nn.Linear(2880, 1728),\n","            nn.ReLU(),\n","            #nn.Dropout(p=0.25),\n","\n","            # Output Layer\n","            nn.Linear(1728, 1),\n","            # Apply Sigmoid activation in order to get a smoother probability\n","            #   curve, which is required by the BinaryCrossEntropy Loss function\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, x):\n","        # Image tx\n","        x = self.conv0(x)\n","\n","        # convolutions\n","        x = self.conv(x)\n","\n","        # FC layers\n","        x = self.fc(x)\n","\n","        return x"]},{"cell_type":"code","source":["class nn_debug(nn.Module):\n","    def __init__(self, debug):\n","        super(nn_debug, self).__init__()\n","        self.debug = debug\n","\n","    def forward(self, x):\n","        if self.debug:\n","            print(f'## Input: {x.shape}')\n","        return x"],"metadata":{"id":"EAzb_sK97Axj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"FKBT929mFihW"},"execution_count":null,"outputs":[]}]}